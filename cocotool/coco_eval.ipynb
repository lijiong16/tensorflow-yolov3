{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "import shutil\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngt_anno=[]\\nimg=[]\\nid=0\\nfor root, dirs, files in os.walk(\"../mAP/ground-truth/\"):\\n    for file in files:\\n        lines=ReadTxt(root+file)\\n        for line in lines:\\n            tmp=line.split(\\' \\')[1:]\\n            tmp_anno={\"image_id\":int(file[:-4]),\\n                      \"category_id\":0,\\n                      \"bbox\":list(map(float,tmp)),\\n                     \"id\":id,\\n                     \"iscrowd\":0}\\n            \\n            gt_anno.append(tmp_anno)\\n            img.append({\"id\":id})\\n            id+=1\\nwith open(\"gt_eval.json\", \"w\") as outfile:\\n    json.dump({\"images\":img,\\n               \"annotations\":gt_anno,\\n                \"categories\": [{\"supercategory\": \"person\", \"id\": 0, \"name\": \"person\"}]}, outfile)\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pdb\n",
    "p=pdb.set_trace\n",
    "def ReadTxt(rootdir):\n",
    "    lines = []\n",
    "    with open(rootdir, 'r') as file_to_read:\n",
    "        while True:\n",
    "            line = file_to_read.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip('\\n')\n",
    "            lines.append(line)\n",
    "    return lines\n",
    "\n",
    "\n",
    "pre_anno=[]\n",
    "for root, dirs, files in os.walk(\"./predicted/\"):\n",
    "    for file in files:\n",
    "        lines=ReadTxt(root+file)\n",
    "        for line in lines:\n",
    "            tmp=line.split(' ')[2:]\n",
    "            bbox=list(map(float,tmp))\n",
    "            tmp_anno={\"image_id\":int(file[:-4]),\n",
    "                      \"category_id\":1,\n",
    "                      \"bbox\":[bbox[0],bbox[1],bbox[2]-bbox[0],bbox[3]-bbox[1]],\n",
    "                      \"score\":float(line.split(' ')[1])}\n",
    "            pre_anno.append(tmp_anno)\n",
    "with open(\"pre_eval.json\", \"w\") as outfile:\n",
    "    json.dump(pre_anno, outfile)\n",
    "\n",
    "\"\"\"\n",
    "gt_anno=[]\n",
    "img=[]\n",
    "id=0\n",
    "for root, dirs, files in os.walk(\"../mAP/ground-truth/\"):\n",
    "    for file in files:\n",
    "        lines=ReadTxt(root+file)\n",
    "        for line in lines:\n",
    "            tmp=line.split(' ')[1:]\n",
    "            tmp_anno={\"image_id\":int(file[:-4]),\n",
    "                      \"category_id\":0,\n",
    "                      \"bbox\":list(map(float,tmp)),\n",
    "                     \"id\":id,\n",
    "                     \"iscrowd\":0}\n",
    "            \n",
    "            gt_anno.append(tmp_anno)\n",
    "            img.append({\"id\":id})\n",
    "            id+=1\n",
    "with open(\"gt_eval.json\", \"w\") as outfile:\n",
    "    json.dump({\"images\":img,\n",
    "               \"annotations\":gt_anno,\n",
    "                \"categories\": [{\"supercategory\": \"person\", \"id\": 0, \"name\": \"person\"}]}, outfile)\n",
    "\"\"\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "annType = ['segm','bbox','keypoints']\n",
    "annType = annType[1]      #specify type here\n",
    "prefix = 'person_keypoints' if annType=='keypoints' else 'instances'\n",
    "#print 'Running demo for *%s* results.'%(annType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.41s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#initialize COCO ground truth api\n",
    "#dataDir='../'\n",
    "#dataType='val2014'\n",
    "#annFile = '%s/annotations/%s_%s.json'%(dataDir,prefix,dataType)\n",
    "annFile=('../data/dataset/instances_val2017.json')\n",
    "cocoGt=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#initialize COCO detections api\n",
    "#resFile='%s/results/%s_%s_fake%s100_results.json'\n",
    "#resFile = resFile%(dataDir, prefix, dataType, annType)\n",
    "resFile=('pre_eval.json')\n",
    "cocoDt=cocoGt.loadRes(resFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgIds=sorted(cocoGt.getImgIds())\n",
    "#imgIds=imgIds[0:100]\n",
    "#imgId = imgIds[np.random.randint(100)]\n",
    "import json \n",
    "dts = json.load(open(resFile,'r'))\n",
    "imgIds = [imid['image_id'] for imid in dts]\n",
    "imgIds = sorted(list(set(imgIds)))\n",
    "del dts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.90s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.24s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.745\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.461\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.490\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.740\n"
     ]
    }
   ],
   "source": [
    "# running evaluation\n",
    "cocoEval = COCOeval(cocoGt,cocoDt,annType)\n",
    "cocoEval.params.imgIds  = imgIds\n",
    "cocoEval.params.catIds = [1]\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './predicted/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-21ec2ae8fc4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./predicted/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;31m# lstat()/open()/fstat() trick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './predicted/'"
     ]
    }
   ],
   "source": [
    "# del tmptxt\n",
    "#shutil.rmtree(\"./predicted/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
